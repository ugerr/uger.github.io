---
---

@string{aps = {American Physical Society,}}

@Article{rs14236058,
AUTHOR = {Yao, Canming and Xie, Pengfei and Zhang, Lei and Fang, Yuyuan},
TITLE = {ATSD: Anchor-Free Two-Stage Ship Detection Based on Feature Enhancement in SAR Images},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {23},
ARTICLE-NUMBER = {6058},
URL = {https://www.mdpi.com/2072-4292/14/23/6058},
ISSN = {2072-4292},
ABSTRACT = {Syntheticap erture radar (SAR) ship detection in harbors is challenging due to the similar backscattering of ship targets to surrounding background interference. Prevalent two-stage ship detectors usually use an anchor-based region proposal network (RPN) to search for the possible regions of interest on the whole image. However, most pre-defined anchor boxes are redundantly and randomly tiled on the image, manifested as low-quality object proposals. To address these issues, this paper proposes a novel detection method combined with two feature enhancement modules to improve ship detection capability. First, we propose a flexible anchor-free detector (AFD) to generate fewer but higher-quality proposals around the object centers in a keypoint prediction manner, which completely avoids the complicated computation in RPN, such as calculating overlapping related to anchor boxes. Second, we leverage the proposed spatial insertion attention (SIA) module to enhance the feature discrimination between ship targets and background interference. It accordingly encourages the detector to pay attention to the localization accuracy of ship targets. Third, a novel weighted cascade feature fusion (WCFF) module is proposed to adaptively aggregate multi-scale semantic features and thus help the detector boost the detection performance of multi-scale ships in complex scenes. Finally, combining the newly-designed AFD and SIA/WCFF modules, we present a new detector, named anchor-free two-stage ship detector (ATSD), for SAR ship detection under complex background interference. Extensive experiments on two public datasets, i.e., SSDD and HRSID, verify that our ATSD delivers state-of-the-art detection performance over conventional detectors.},
DOI = {10.3390/rs14236058},
abbr={Remote Sensing},
preview={ATSD.png},
pdf={https://www.mdpi.com/2072-4292/14/23/6058},
selected={true},
}

@INPROCEEDINGS{10050663,
  author={Yao, Canming and Li, Chao and Jin, Xue and Zhang, Lei},
  booktitle={2022 5th International Conference on Information Communication and Signal Processing (ICICSP)}, 
  title={A Fast Two-Parameter CFAR Algorithm Based on FFT for Ship Detection in Large-Scale SAR Images}, 
  year={2022},
  pages={244-248},
  keywords={Parameter estimation;Signal processing algorithms;Clustering algorithms;Radar detection;Object detection;Radar imaging;Radar polarimetry;ship detection;constant false alarm rate (CFAR);fast Fourier transform (FFT);synthetic aperture radar (SAR)},
  abstract = {Ship target detection in synthetic aperture radar (SAR) images via the classical constant false alarm rate (CFAR) algorithm is an important technique. However, each pixel in local sliding window detection is involved in parameter estimation multiple times, which leads to computational inefficiency, especially for large-scale SAR images. To solve the above issue, this paper proposes a fast two-parameter CFAR algorithm based on fast Fourier transform (FFT), named F2T-CFAR. First, FFT is employed to replace the sliding window detection and statistical properties are obtained by global computation. Second, we extract potential target points from the global detection results by threshold decision and subsequently cluster these potential points using the density-based spatial clustering of applications with noise (DBSCAN) algorithm to obtain the final ship target centers. Our F2T-CFAR significantly improves the computational speed compared to the two-threshold CFAR method. Experiments on the measured large-scale SAR images demonstrate the effectiveness of our F2T-CFAR algorithm.},
  doi={10.1109/ICICSP55539.2022.10050663},
  abbr={ICICSP 2022},
  preview={FT-CFAR.png},
  pdf={https://ieeexplore.ieee.org/abstract/document/10050663},
  selected={true},
  }

@article{https://doi.org/10.1155/2022/7537732,
author = {Hu, Liping and Yao, Canming and Huang, Jian and Liu, Jinfan and Wang, Guanyong},
title = {Highly Robust Synthetic Aperture Radar Target Recognition Method Based on Simulation Data Training},
journal = {International Journal of Antennas and Propagation},
volume = {2022},
number = {1},
pages = {7537732},
doi = {https://doi.org/10.1155/2022/7537732},
abstract = {Sufficient synthetic aperture radar (SAR) data is the key element in achieving excellent target recognition performance for most deep learning algorithms. It is unrealistic to obtain sufficient SAR data from the actual measurements, so SAR simulation based on electromagnetic scattering modeling has become an effective way to obtain sufficient samples. Simulated and measured SAR images are nonhomologous data. Due to the fact that the target geometric model of SAR simulation is not inevitably consistent with the real object, the SAR sensor model in SAR simulation may be different from the actual sensor, the background environment of the object is also inevitably different from that of SAR simulation, the error of electromagnetic modeling method itself, and so on. There are inevitable differences between the simulated and measured SAR images, which will affect the recognition performance. To address this problem, an SAR simulation method based on a high-frequency asymptotic technique and a discrete ray tracing technique is proposed in this paper to obtain SAR simulation images of ground vehicle targets. Next, various convolutional neural networks (CNNs) and AugMix data augmentation methods are proposed to train only on simulated data, and then target recognition on MSTAR measured data is performed. The experiments show that all the CNNs can achieve incredible recognition performance on the nonhomologous SAR data, and the RegNetX-3.2GF achieves state-of-the-art performance, up to 84.81\%.},
year = {2022},
abbr={IJAP},
preview={IJAP.png},
pdf={https://onlinelibrary.wiley.com/doi/full/10.1155/2022/7537732},
selected={true},
}

